{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<img src=\"/home/mauricio/Documents/Projects/RAG-Mastery/Diagrams/RAG-chat-history.png\" width=\"65%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We'll start by copying and reusing certain components from our Simple_rag implementation:\n",
    "\n",
    "- Document loading\n",
    "- Text splitting\n",
    "- Document retrieval\n",
    "\n",
    "These components will remain largely unchanged, as they form the foundation of our RAG system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tqdm as notebook_tqdm\n",
    "from typing import List, Union\n",
    "\n",
    "# Path to the directory containing config.py\n",
    "config_path = '/home/mauricio/Documents/Projects/RAG-Mastery'\n",
    "\n",
    "# Add the directory to sys.path\n",
    "if config_path not in sys.path:\n",
    "    sys.path.append(config_path)\n",
    "\n",
    "# Now you can import the API_KEY from config.py\n",
    "from config import API_KEY\n",
    "\n",
    "path_to_docs = \"/home/mauricio/Documents/Projects/RAG-Mastery/data\"\n",
    "\n",
    "import warnings\n",
    "# Suppress the specific warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not download mistral tokenizer\")\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "# Suppress HTTP request logs\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "# Suppress FAISS logs\n",
    "logging.getLogger(\"faiss\").setLevel(logging.WARNING)\n",
    "\n",
    "# Suppress pikepdf logs\n",
    "logging.getLogger(\"pikepdf\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "def get_llm_model():\n",
    "        return ChatMistralAI(\n",
    "            model_name=\"open-mixtral-8x22b\", \n",
    "            mistral_api_key=API_KEY\n",
    "        )\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def load_documents(folder_path):\n",
    "    documents = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.docx') or file.endswith('.pdf') or file.endswith('.txt'):\n",
    "            loader = UnstructuredLoader(os.path.join(folder_path, file))\n",
    "            documents.extend(loader.load())\n",
    "        print(\"Document loaded lenght: \", len(documents))\n",
    "    print(\"Documents loaded successfully ✅\")\n",
    "    print(documents[0].metadata.get(\"filename\"))\n",
    "    return documents\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def split_documents(documents, chunk_size= 1000, chunk_overlap= 200):\n",
    "        try:\n",
    "            text_splitter: RecursiveCharacterTextSplitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap,\n",
    "                length_function=len,\n",
    "                separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "            )\n",
    "            splits: List[Document] = text_splitter.split_documents(documents)\n",
    "            print(\"Split document successfully ✅\")\n",
    "            print(\"Documents split: \", len(splits))\n",
    "            return splits\n",
    "        except Exception as e:\n",
    "            print(f\"Error splitting documents: {e}\")\n",
    "            raise\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def embed_documents(splits):\n",
    "    try:\n",
    "        embeddings = MistralAIEmbeddings(\n",
    "            model=\"mistral-embed\",\n",
    "            mistral_api_key=API_KEY\n",
    "            )\n",
    "        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "        retriever = vectorstore.as_retriever(\n",
    "            search_type=\"mmr\",\n",
    "            search_kwargs={\"k\": 6},\n",
    "        )\n",
    "\n",
    "        print(\"Retriever succesfuly created ✅\")\n",
    "        return retriever\n",
    "    except Exception as e:\n",
    "        print(f\"Error embeding/retrieving documents {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now focusing on enhancing our RAG system with a sophisticated chat history component, this involves creating a sub-chain that reformulates the user's latest question by incorporating context from the entire conversation history. \n",
    "\n",
    "$$\n",
    "(query, conversation\\hspace{0.1cm}history) --> LLM --> rephrased\\hspace{0.1cm}query --> retriever\n",
    "$$\n",
    "\n",
    "This process allows us to maintain conversation fluently while ensuring that each query to the retriever is relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"You are an AI assistant specializing in contextual analysis and question reformulation for an NFL rulebook system. Your task is to:\n",
    "\n",
    "        1. Carefully analyze the provided chat history and the latest user question.\n",
    "        2. Identify any contextual references or implied information from the chat history that are relevant to the latest question.\n",
    "        3. Reformulate the question into a standalone format that incorporates all necessary context.\n",
    "        4. Ensure the reformulated question can be fully understood without access to the chat history.\n",
    "        5. If the original question is already standalone and doesn't require additional context, return it unchanged.\n",
    "\n",
    "        Key Instructions:\n",
    "        - Focus solely on reformulation; do not attempt to answer the question.\n",
    "        - Maintain the original intent and scope of the question.\n",
    "        - Use clear, concise language appropriate for an NFL rulebook context.\n",
    "        - Include specific NFL terminology or references if they were part of the original context.\n",
    "\n",
    "        Example:\n",
    "        Original: \"What's the penalty for that?\"\n",
    "        Reformulated: \"What is the specific penalty for defensive pass interference in the NFL?\"\n",
    "\n",
    "        Output: Provide only the reformulated question or the original question if no reformulation is needed. Do not include any explanations or additional commentary.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build the QA chain for the RAG. We will use the $history_aware_retriever$ function form lagchain. \n",
    "\n",
    "Also to generate the chain we have to use question_answer_chain with the context, chat_history and the $input$ as the input keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"\n",
    "        You are an expert NFL rulebook assistant specializing in concise, accurate answers. \n",
    "        Your primary function is to provide clear and precise responses to questions about NFL rules and regulations. \n",
    "        Key Instructions:\n",
    "            1. Analyze the provided context carefully.\n",
    "            2. Use only the given context to formulate your answer. Do not rely on external knowledge.\n",
    "            3. If the context doesn't contain sufficient information to answer the question, respond with 'I don't have enough information to answer that question based on the provided context.\n",
    "            4. Limit your response to a maximum of three sentences.\n",
    "            5. Prioritize clarity and accuracy over exhaustive explanations.\n",
    "            6. If relevant, cite the specific NFL rule or section number.\n",
    "            7. Avoid speculation or personal opinions.\n",
    "            \n",
    "        Context:\n",
    "        {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the:\n",
    "\n",
    "* history_aware_retrieve\n",
    "\n",
    "* question_answer_chain\n",
    "\n",
    "* rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded lenght:  1964\n",
      "Documents loaded successfully ✅\n",
      "2024-nfl-rulebook.pdf\n",
      "Split document successfully ✅\n",
      "Documents split:  1995\n",
      "Retriever succesfuly created ✅\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "documents = load_documents(path_to_docs)\n",
    "splits = split_documents(documents)\n",
    "retriever = embed_documents(splits)\n",
    "\n",
    "llm = get_llm_model()\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt)\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to try it!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Chat History: []\n",
      "🟠 Answer: The new rule for kickoffs in the 2024 NFL season is that after the kick, the kicker may not cross the vicinity of the 50-yard line until the ball touches the ground or a player. Additionally, there is a new toss option for both halves and overtime, and a loss of 15 yards from the spot of the kickoff for the first half.\n"
     ]
    }
   ],
   "source": [
    "result = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are the new rules for kickoffs in the NFL for the 2024 season?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"nfl_rules_2024\"}\n",
    "    }\n",
    ")\n",
    "print(f\"🔵 Chat History: {result['chat_history']}\")\n",
    "print(f\"🟠 Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Chat History: [HumanMessage(content='What are the new rules for kickoffs in the NFL for the 2024 season?'), AIMessage(content='The new rule for kickoffs in the 2024 NFL season is that after the kick, the kicker may not cross the vicinity of the 50-yard line until the ball touches the ground or a player. Additionally, there is a new toss option for both halves and overtime, and a loss of 15 yards from the spot of the kickoff for the first half.')]\n",
      "🟠 Answer: The new kickoff rules state that if an onside kick goes untouched beyond the onside kick setup zone, the kicking team will be penalized 15 yards from the kicking team's restraining line and the receiving team will take possession. This will make onside kick attempts more difficult for the kicking team.\n"
     ]
    }
   ],
   "source": [
    "result_2 = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"How do these new kickoff rules affect onside kick attempts?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"nfl_rules_2024\"}\n",
    "    }\n",
    ")\n",
    "print(f\"🔵 Chat History: {result_2['chat_history']}\")\n",
    "print(f\"🟠 Answer: {result_2['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Chat History: [HumanMessage(content='What are the new rules for kickoffs in the NFL for the 2024 season?'), AIMessage(content='The new rule for kickoffs in the 2024 NFL season is that after the kick, the kicker may not cross the vicinity of the 50-yard line until the ball touches the ground or a player. Additionally, there is a new toss option for both halves and overtime, and a loss of 15 yards from the spot of the kickoff for the first half.'), HumanMessage(content='How do these new kickoff rules affect onside kick attempts?'), AIMessage(content=\"The new kickoff rules state that if an onside kick goes untouched beyond the onside kick setup zone, the kicking team will be penalized 15 yards from the kicking team's restraining line and the receiving team will take possession. This will make onside kick attempts more difficult for the kicking team.\")]\n",
      "🟠 Answer: Teams may choose to declare an onside kick if they are trailing in the fourth period, providing an opportunity to regain possession of the ball. Additionally, teams may employ a strategy of scoring a touchdown on their initial possession in overtime to win the game, rather than relying on a field goal attempt.\n"
     ]
    }
   ],
   "source": [
    "result_3 = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Given these changes, what strategies might teams adopt for late-game situations when they're trailing?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"nfl_rules_2024\"}\n",
    "    }\n",
    ")\n",
    "print(f\"🔵 Chat History: {result_3['chat_history']}\")\n",
    "print(f\"🟠 Answer: {result_3['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Chat History: [HumanMessage(content='What are the new rules for kickoffs in the NFL for the 2024 season?'), AIMessage(content='The new rule for kickoffs in the 2024 NFL season is that after the kick, the kicker may not cross the vicinity of the 50-yard line until the ball touches the ground or a player. Additionally, there is a new toss option for both halves and overtime, and a loss of 15 yards from the spot of the kickoff for the first half.'), HumanMessage(content='How do these new kickoff rules affect onside kick attempts?'), AIMessage(content=\"The new kickoff rules state that if an onside kick goes untouched beyond the onside kick setup zone, the kicking team will be penalized 15 yards from the kicking team's restraining line and the receiving team will take possession. This will make onside kick attempts more difficult for the kicking team.\"), HumanMessage(content=\"Given these changes, what strategies might teams adopt for late-game situations when they're trailing?\"), AIMessage(content='Teams may choose to declare an onside kick if they are trailing in the fourth period, providing an opportunity to regain possession of the ball. Additionally, teams may employ a strategy of scoring a touchdown on their initial possession in overtime to win the game, rather than relying on a field goal attempt.')]\n",
      "🟠 Answer: The 2024 rule changes for kickoffs limit the number of players on the field, potentially reducing the number of collisions and impact injuries. Additionally, the new rules for enforcing fouls prior to the change of possession may discourage aggressive play, further reducing the risk of injury.\n"
     ]
    }
   ],
   "source": [
    "result_4 = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"How do the 2024 rule changes for kickoffs and late-game strategies impact player safety, especially for special teams players?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"nfl_rules_2024\"}\n",
    "    }\n",
    ")\n",
    "print(f\"🔵 Chat History: {result_4['chat_history']}\")\n",
    "print(f\"🟠 Answer: {result_4['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rag_mastery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
